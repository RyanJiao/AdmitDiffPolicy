<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Admittance Visuomotor Policy for Contact-Rich
        Manipulation Tasks with Hand-Arm Teleoperation.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Admittance Visuomotor Policy for Contact-Rich Manipulation Tasks with Hand-Arm Teleoperation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- 题目， 作者， 链接 部分 -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Admittance Visuomotor Policy Learning for General-Purpose Contact-Rich Manipulations</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://ieeexplore.ieee.org/author/37957753600">Bo Zhou, <i>Member, IEEE</i>,</a>
            <span class="author-block">
              <a href="https://utkarshsinha.com">Ruixuan Jiao</a>,</span>
            <span class="author-block">
              <a href="https://yolo01826.github.io/">Yi Li</a>,
            </span>
            <span class="author-block">
              <a href="https://ieeexplore.ieee.org/author/37088578595">Xiaogang Yuan</a>,
            </span>
            <br>
            <span class="author-block">
              <a href="https://ieeexplore.ieee.org/author/37529151500">Fang Fang</a>,
            </span>
            <span class="author-block">
              <a href="https://ieeexplore.ieee.org/author/37310205600">Shihua Li, <i>Fellow, IEEE</i> </a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Southeast University</span>
            <!-- <span class="author-block"><sup>2</sup>Google Research</span> -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <!-- arixv link -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2409.14440"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=LDSjkn_cWbQ&feature=youtu.be"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/RyanJiao/AdmitDiffPolicy"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- 正文部分 从视频网格到图片 -->
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item open_left_door_mute">
          <video poster="" id="open_left_door_mute" autoplay controls muted loop playsinline height="100%">
            <source src="static/videos/Insertion.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item open_cabinet_drawer_mute">
          <video poster="" id="open_cabinet_drawer_mute" autoplay controls muted loop playsinline height="100%">
            <source src="static/videos/Wipe.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item open_right_door_mute">
          <video poster="" id="open_right_door_mute" autoplay controls muted loop playsinline height="100%">
            <source src="static/videos/Drag.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item open_top_drawer_mute">
          <video poster="" id="open_top_drawer_mute" autoplay controls muted loop playsinline height="100%">
            <source src="static/videos/Open.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item open_washing_machine_mute">
          <video poster="" id="open_washing_machine_mute" autoplay controls muted loop playsinline height="100%">
            <source src="static/videos/Draw.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
  

<!-- 大图
<section class="section">
  <div class="column is-six-fifths">
    <img id="framework" width="100%" src="static/images/general_fig.png">
  </div>
</section> -->

<!-- 摘要文字 -->
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Operating smoothly in contact-rich environments is crucial for robots to effectively perform 
            daily tasks. Leveraging contact force information can enhance the smoothness of interactive 
            operations, force control should be addressed throughout the entire process of autonomous 
            policy development, from data collection, training to deployment.
          </p>
          <p>
            we propose an admittance imitation learning visuomotor policy framework to reduce mean contact 
            force and force fluctuations. Our framework utilizes RGB images, robot joint positions, end-effector 
            poses, and contact force as inputs, employing a diffusion model to generate future end-effector 
            trajectories and contact force.
          </p>
          <p>
            An admittance controller is employed
            to track this trajectories, enabling effective force control
            for various tasks. Furthermore, a low-cost hand-arm teleoperation system with interactive feedback is designed for
            data collection. A evaluation of our teleoperation system
            and policy framework was conducted on five contact-rich
            manipulation tasks, each representing an action primitive.
            Results show that our framework achieves the highest success rate and demonstrates smoother contact compared
            to other methods. Particularly for door opening task, the
            average contact force is reduced by <strong>53.92%</strong>, while the standard deviation of contact force fluctuations is diminished
            by <strong>76.51%</strong>.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    
    <!-- youtube视频 -->

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <!-- <iframe src="https://www.youtube.com/watch?v=LDSjkn_cWbQ&feature=youtu.be"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->

          <iframe src="https://www.youtube.com/embed/LDSjkn_cWbQ?si=ECH2ieCTTU1OagOj" 
            frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
               <!-- frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe> -->
        </div>
      </div>
    </div>

  </div>
</section>


  <!-- 整体方法 -->
  <section class="section">
    <div class="container is-max-desktop">
      <!-- Method -->
        <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths">
          <h2 class="title is-3">AdmitDiff Policy Framework</h2>

          <h3 class="has-text-centered">
            <div class="content has-text-justified">
            <p>AdmitDiff Policy Framework. Left: During inference, the previous two steps’ observations are encoded as inputs for noise estimation, while
              the student model outputs actions for the next 8 time steps, the number K represents the denoising iteration required by the diffuser. The arm’s
              force-position trajectory is used in the admittance controller to compute the desired pose. Middle: The teacher model is trained for 100 denoising
              steps, then its parameters are frozen to train the student model with a consistency loss for single-step denoising. Right: Data collection, including
              contact force information, is performed using the teleoperation system designed in this work.              
            </p>
          </div>
          </h3>

          <img id="framework" width="110%" src="static/images/policy_all.png">

        </div>
      </div>
    </div>
  </section>

  <!-- 遥操作 -->
  <section class="section">
    <div class="container is-max-desktop">
      <!-- Method -->
        <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths">
          <h2 class="title is-3">Robot Teleoperation System</h2>

          <h3 class="has-text-centered">
            <div class="content has-text-justified">
              <p>There are three main components that provide critical data for the teleoperation task.</p>
              <ol>
                <li>
                  <strong>Wrist spatial pose control module:</strong> It estimates the 6-DoF position and orientation of the wearer’s wrist using the Intel RealSense Tracking Camera T265. 
                  The Intel RealSense T265 integrates Stereo cameras and an IMU to run Visual-Inertial Odometry to provide accurate spatial odometry. 
                  Following the approach in [9], we designed a simple glove using Velcro and 3D-printed parts to securely mount the T265 on the operator’s palm.
                </li>
                <li>
                  <strong>Gesture detection and remapping module:</strong> It uses the Ultraleap Leap Motion Controller to estimate the keypoints coordinates of human hand gestures.
                  Then it generates the joint angles of a multi-fingered robotic hand based on detected human hand gestures, allowing precise gesture-based interaction with the robot.
                </li>
                <li>
                  <strong>Wrist-mounted force feedback module:</strong> It uses Eccentric Rotating Mass (ERM) vibration motors attached to the operator’s palm.
                  Our system uses an stm32f103c8t6 microcontroller to generate Pulse Width Modulation (PWM) signals for a NPN Bipolar Junction Transistor, 
                  based on force data from the wrist Force/Torque sensor. Contact forces between 0-20N are mapped linearly to vibration intensity, 
                  providing real-time feedback to the operator, similar to the approach in [27].
                </li>
              </ol>
            </div>

            <img id="framework" width="60%" src="static/images/teleop.png">
          </div>
          </h3>    
        </div>



      </div>
    </div>
  </section>

  <!-- open_left_door -->
  <div class="container is-max-desktop">
    <div class="columns is-centered">
        
      <!-- Behavior Cloning -->
      <div class="column">
        <div class="content">
          <p>Open Box</p>
          <video id="open_left_door_bc" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/tele_openbox.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>

      <!-- MOMA -->
      <div class="column">
        <div class="content">
          <p>Rotate Box</p>
          <video id="open_left_door_moma" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/tele_rotatbox.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>

      <!-- MOMA-Force -->
      <div class="column">
        <div class="content">
          <p>Drag</p>
          <video id="open_left_door_moma_force" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/tele_drag.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>


    </div>
  </div>


<!-- 结果 -->
<section class="section">
  <div class="container is-max-desktop">
    <!-- Method -->
      <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3">Results</h2>
        <img id="framework" width="50%" src="static/images/boxplot.png">
        <h3 class="has-text-centered">
          <div class="content has-text-justified">
          <p>AdmitDiff Policy consistently demonstrates the most stable contact force control, with lower variance and more controlled median force, especially in tasks like Insertion and Wiping that require precision. In contrast, Diffusion Policy and Consistency Policy exhibit higher variance, particularly in force-intensive tasks like DoorOpening, indicating less stable control. 

            The AdmitDiff Policy shows an average reduction of approximately <strong>48.8%</strong> in mean contact force and <strong>52.0%</strong> in standard deviation compared to the other methods in the five tasks.
          </p>
        </div>
        </h3>
      </div>
    </div>
  </div>
</section>


<!-- 九宫格视频 -->
<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">

      <div class="column">
        <div class="content">
          <p>Behavior Cloning (BC)</p>
          <video id="BC" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/comp/open_right_door_bc_720.mov"
                    type="video/mp4">
          </video>
        </div>
      </div>

      <div class="column">
        <div class="content">
          <p>MOMA-Force w/o FC</p>
          <video id="MOMA" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/comp/open_right_door_moma_720.mov"
                    type="video/mp4">
          </video>
        </div>
      </div>

      <div class="column">
        <div class="content">
          <p>MOMA-Force</p>
          <video id="MOMA-Force" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/comp/open_right_door_moma_force_720.mov"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>

  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <video id="open_left_door_bc" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/comp/open_left_door_bc_720.mov"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <div class="column">
        <div class="content">
          <video id="open_left_door_moma" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/comp/open_left_door_moma_720.mov"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <div class="column">
        <div class="content">
          <video id="open_left_door_moma_force" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/comp/open_left_door_moma_force_720.mov"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>


  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <video id="rotate_tap_bc" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/comp/rotate_tap_bc_720.mov"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <div class="column">
        <div class="content">
          <video id="rotate_tap_moma" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/comp/rotate_tap_moma_720.mov"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <div class="column">
        <div class="content">
          <video id="rotate_tap_moma_force" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/comp/rotate_tap_moma_force_720.mov"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->

<!-- 相关链接 -->
<!-- <section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div>

  </div>
</section> -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{bo@2024admitdiff,
  author    = {Bo Zhou, Ruixuan Jiao, Yi Li, Xiaogang Yuan, Fang Fang, Shihua Li,},
  title     = {Admittance Visuomotor Policy Learning for General-Purpose Contact-Rich Manipulations},
  journal   = {arXiv preprint arXiv:2409.14440},
  year      = {2024},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
        <div class="content">
          <p>
            The website template was adapted from <a
              href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
          </p>
        </div>
      </div>
  </div>
</footer>


</body>
</html>
